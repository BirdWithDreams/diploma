{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:36:50.108129Z",
     "start_time": "2024-08-19T08:36:49.916107Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796e55ad138c59c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:36:57.849226Z",
     "start_time": "2024-08-19T08:36:57.830964Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('keithito/lj_speech', cache_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ac514d7fc51324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:37:49.167726Z",
     "start_time": "2024-08-19T08:37:49.155277Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train']['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc95122e740d8563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T08:37:56.082588Z",
     "start_time": "2024-08-19T08:37:56.062455Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reformat_dataset(output_dir):\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset('keithito/lj_speech', cache_dir='../data')\n",
    "\n",
    "    # Create output directory structure\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    wavs_dir = os.path.join(output_dir, \"wavs\")\n",
    "    os.makedirs(wavs_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare metadata file\n",
    "    metadata_path = os.path.join(output_dir, \"metadata.txt\")\n",
    "\n",
    "    with open(metadata_path, 'w', newline='', encoding='utf-8') as metadata_file:\n",
    "        writer = csv.writer(metadata_file, delimiter='|')\n",
    "\n",
    "        # Iterate through the dataset\n",
    "        for item in tqdm(dataset['train'], desc=\"Processing items\"):\n",
    "            # Generate a filename for the audio\n",
    "            audio_filename = f\"{item['id']}.wav\"\n",
    "\n",
    "            # Save the audio file\n",
    "            audio_path = os.path.join(wavs_dir, audio_filename)\n",
    "            sf.write(audio_path, item['audio']['array'], item['audio']['sampling_rate'])\n",
    "\n",
    "            # Write metadata\n",
    "            writer.writerow([\n",
    "                audio_filename.replace('.wav', ''),\n",
    "                item['text'],\n",
    "                item['normalized_text']\n",
    "            ])\n",
    "\n",
    "    print(f\"Dataset reformatted and saved to {output_dir}\")\n",
    "\n",
    "# Usage\n",
    "output_directory = \"../data/keithito_lj_speech\"\n",
    "reformat_dataset(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfba8d30af7f8ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T09:34:19.156320Z",
     "start_time": "2024-08-14T09:34:19.134357Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def split_metadata(input_file, train_file, test_file, train_ratio=0.8):\n",
    "    # Read all lines from the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Shuffle the lines randomly\n",
    "    random.shuffle(lines)\n",
    "\n",
    "    # Calculate the split point\n",
    "    split_point = int(len(lines) * train_ratio)\n",
    "\n",
    "    # Write train data\n",
    "    with open(train_file, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines[:split_point])\n",
    "\n",
    "    # Write test data\n",
    "    with open(test_file, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines[split_point:])\n",
    "\n",
    "    print(f\"Total lines: {len(lines)}\")\n",
    "    print(f\"Train lines: {split_point}\")\n",
    "    print(f\"Test lines: {len(lines) - split_point}\")\n",
    "\n",
    "# Usage\n",
    "input_metadata = \"../data/keithito_lj_speech/metadata.txt\"\n",
    "train_metadata = \"../data/keithito_lj_speech/train_metadata.txt\"\n",
    "test_metadata = \"../data/keithito_lj_speech/test_metadata.txt\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.dirname(train_metadata), exist_ok=True)\n",
    "\n",
    "# Perform the split\n",
    "split_metadata(input_metadata, train_metadata, test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f27ab58ca34ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
